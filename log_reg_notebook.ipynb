{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from features import topological_features, aggregate_features, get_vars, extract_features\n",
    "import pickle\n",
    "import rolx\n",
    "import numpy as np\n",
    "import utils\n",
    "import random\n",
    "\n",
    "def get_scores(train_pred, train_true, val_pred, val_true, test_pred, test_true):\n",
    "    train_accuracy = np.mean(train_pred == train_true)\n",
    "    print (train_accuracy)\n",
    "\n",
    "    train_f1 =  precision_recall_fscore_support(train_true, train_pred)\n",
    "    print (train_f1[0][1])\n",
    "    print (train_f1[1][1])\n",
    "    print (train_f1[2][1])\n",
    "    \n",
    "    val_accuracy = np.mean(val_pred == val_true)\n",
    "    print (val_accuracy)\n",
    "    \n",
    "    val_f1 =  precision_recall_fscore_support(val_true, val_pred)\n",
    "    print (val_f1[0][1])\n",
    "    print (val_f1[1][1])\n",
    "    print (val_f1[2][1])\n",
    "\n",
    "    test_accuracy = np.mean(test_pred == test_true)\n",
    "    print (test_accuracy)\n",
    "    \n",
    "    test_f1 =  precision_recall_fscore_support(test_true, test_pred)\n",
    "    print (test_f1[0][1])\n",
    "    print (test_f1[1][1])\n",
    "    print (test_f1[2][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolx(fname, fname_extended, roles=3):\n",
    "    G, dict_to_graph, graph_to_dict = rolx.load_graph_igraph(fname, fname_extended)\n",
    "    H, R = rolx.extract_rolx_roles(G, roles)\n",
    "    print(H.shape, R.shape)\n",
    "    H.tolist()\n",
    "\n",
    "    adj_mat = G.get_adjacency()\n",
    "    _, video_dict_list, graph_to_dict, neighbors, fields = get_vars(fname, fname_extended)\n",
    "    # np.save('rolx_features', H)\n",
    "    # H = np.load('rolx_features.npy')\n",
    "    \n",
    "    return adj_mat, H, video_dict_list, graph_to_dict, neighbors, fields\n",
    "\n",
    "def get_features(adj_mat, H, video_dict_list, graph_to_dict, neighbors, fields, agg_flag=False):\n",
    "    X = []\n",
    "    y = []\n",
    "    pos_data = []\n",
    "    neg_data = []\n",
    "    for row in range(adj_mat.shape[0]):\n",
    "        H_row = np.array(H[row]).flatten()\n",
    "        for col in range(adj_mat.shape[1]):\n",
    "            H_total = np.array(H[col][0]).flatten() + H_row\n",
    "            # print 'pre concatenated', type(H_total), H_total\n",
    "\n",
    "            # flag for adding into agg and topo features\n",
    "            if agg_flag:\n",
    "                local_features = extract_features(video_dict_list, graph_to_dict, neighbors, fields, row, col) \n",
    "                # skip if doesnt exist\n",
    "                if not local_features:\n",
    "                    continue\n",
    "\n",
    "                H_total = np.concatenate([H_total, local_features]) \n",
    "                # print 'after concatenated', type(H_total), H_total\n",
    "\n",
    "            if adj_mat[row][col] > 0:\n",
    "                pos_data.append((H_total, adj_mat[row][col]))\n",
    "            else:\n",
    "                neg_data.append((H_total, adj_mat[row][col]))\n",
    "    \n",
    "    return pos_data, neg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vertex Features matrix\n",
      "V is a 3356 by 485 matrix.\n",
      "Node-role matrix is of dimensions 3356 by 3\n",
      "[[0.         0.0199036  0.00744173]\n",
      " [0.         0.02791589 0.03119776]\n",
      " [0.         0.01000588 0.01839252]\n",
      " ...\n",
      " [0.         0.00740323 0.01428153]\n",
      " [0.         0.00737681 0.01464255]\n",
      " [0.         0.00737681 0.01464255]]\n",
      "[[3.97698502e+04 1.14131367e-01 2.00000000e+01 ... 1.14373638e-03\n",
      "  1.14373638e-03 2.00000000e+01]\n",
      " [6.67290721e+04 1.22706739e-01 4.00000000e+00 ... 2.08546433e-04\n",
      "  2.08546433e-04 4.00000000e+00]\n",
      " [0.00000000e+00 1.11362115e-01 3.00000000e+00 ... 1.85490526e-04\n",
      "  1.85490526e-04 3.00000000e+00]\n",
      " ...\n",
      " [3.33333333e-01 5.58823529e-01 4.00000000e+00 ... 2.06357331e-04\n",
      "  2.06357331e-04 4.00000000e+00]\n",
      " [0.00000000e+00 5.58823529e-01 4.00000000e+00 ... 1.98521122e-04\n",
      "  1.98521122e-04 4.00000000e+00]\n",
      " [0.00000000e+00 5.58823529e-01 4.00000000e+00 ... 1.98521122e-04\n",
      "  1.98521122e-04 4.00000000e+00]]\n",
      "[[0.00408327 0.         0.01162663 0.         0.         0.\n",
      "  0.         0.01162658]\n",
      " [0.00836902 0.07900757 0.09599821 0.06960697 0.04866281 0.06974207\n",
      "  0.06974201 0.09599826]\n",
      " [0.03785696 0.02855227 0.0600203  0.10154982 0.11091528 0.07429601\n",
      "  0.07429492 0.06002027]]\n",
      "Role-feature matrix is of dimensions 3 by 8\n",
      "[[0.00408327 0.         0.01162663 0.         0.         0.\n",
      "  0.         0.01162658]\n",
      " [0.00836902 0.07900757 0.09599821 0.06960697 0.04866281 0.06974207\n",
      "  0.06974201 0.09599826]\n",
      " [0.03785696 0.02855227 0.0600203  0.10154982 0.11091528 0.07429601\n",
      "  0.07429492 0.06002027]]\n",
      "(3356, 3) (3, 8)\n"
     ]
    }
   ],
   "source": [
    "fname = './dataset/0222/0.txt'\n",
    "fname_extended = './dataset/0222/1.txt'\n",
    "\n",
    "adj_mat, H, video_dict_list, graph_to_dict, neighbors, fields = get_rolx(fname, fname_extended)\n",
    "pos_data, neg_data = get_features(adj_mat, H, video_dict_list, graph_to_dict, neighbors, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vertex Features matrix\n",
      "V is a 4330 by 408 matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bao Tran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1770: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node-role matrix is of dimensions 4330 by 3\n",
      "[[0.19925109 0.16108741 0.00058692]\n",
      " [0.07929716 0.13149653 0.05354079]\n",
      " [0.19925109 0.16108741 0.00058692]\n",
      " ...\n",
      " [0.09832276 0.13102633 0.05499859]\n",
      " [0.1229468  0.13840692 0.06407499]\n",
      " [0.08100141 0.12920092 0.08111056]]\n",
      "[[1.27952413e+04 8.77933545e-02 2.00000000e+01 ... 3.99064480e-04\n",
      "  3.99064480e-04 2.00000000e+01]\n",
      " [7.14285714e-01 8.07364935e-02 1.00000000e+01 ... 2.10219785e-04\n",
      "  2.10219785e-04 1.00000000e+01]\n",
      " [1.27952413e+04 8.77933545e-02 2.00000000e+01 ... 3.99064480e-04\n",
      "  3.99064480e-04 2.00000000e+01]\n",
      " ...\n",
      " [1.06668301e+01 5.27777778e-01 1.10000000e+01 ... 2.52185559e-04\n",
      "  2.52185559e-04 1.10000000e+01]\n",
      " [1.25640720e+00 5.50724638e-01 1.20000000e+01 ... 2.52082882e-04\n",
      "  2.52082882e-04 1.20000000e+01]\n",
      " [0.00000000e+00 5.06666667e-01 9.00000000e+00 ... 1.95368248e-04\n",
      "  1.95368248e-04 9.00000000e+00]]\n",
      "[[0.         0.         0.02484641 0.         0.         0.\n",
      "  0.         0.0248456 ]\n",
      " [0.03682037 0.12328192 0.128708   0.15966354 0.13158343 0.12093122\n",
      "  0.12093304 0.1287098 ]\n",
      " [0.         0.         0.         0.         0.00225468 0.\n",
      "  0.         0.        ]]\n",
      "Role-feature matrix is of dimensions 3 by 8\n",
      "[[0.         0.         0.02484641 0.         0.         0.\n",
      "  0.         0.0248456 ]\n",
      " [0.03682037 0.12328192 0.128708   0.15966354 0.13158343 0.12093122\n",
      "  0.12093304 0.1287098 ]\n",
      " [0.         0.         0.         0.         0.00225468 0.\n",
      "  0.         0.        ]]\n",
      "(4330, 3) (3, 8)\n"
     ]
    }
   ],
   "source": [
    "fname_test = './dataset/080327/0.txt'\n",
    "fname_test_extended = './dataset/080327/1.txt'\n",
    "\n",
    "adj_mat_test, H_test, video_dict_list_test, graph_to_dict_test, neighbors_test, fields_test = get_rolx(fname_test, fname_test_extended)\n",
    "pos_data_test, neg_data_test = get_features(adj_mat_test, H_test, video_dict_list_test, graph_to_dict_test, neighbors_test, fields_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_balanced(pos_data, neg_data):\n",
    "    # creates positive and negative dataset for more uniform distribution of data\n",
    "    X = [pos_data[i][0] for i in range(len(pos_data))]\n",
    "    Y = [pos_data[i][1] for i in range(len(pos_data))]\n",
    "\n",
    "    random_indices = sorted(random.sample(range(len(neg_data)), len(X)))\n",
    "    X_neg = [neg_data[i][0] for i in random_indices]\n",
    "    Y_neg = [neg_data[i][1] for i in random_indices]\n",
    "\n",
    "    X.extend(X_neg)\n",
    "    Y.extend(Y_neg)\n",
    "\n",
    "    X_array = np.array(X)\n",
    "    Y_array = np.array(Y)\n",
    "    \n",
    "    print (X_array.shape, Y_array.shape)\n",
    "    from sklearn.preprocessing import normalize\n",
    "    # change this line to change the number of features\n",
    "    X_array = X_array[:, np.r_[:3]]\n",
    "    print (X_array.shape)\n",
    "\n",
    "    # runs training by splitting train/test sets\n",
    "    return train_test_split(X_array, Y_array, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(pos_data, neg_data):\n",
    "    # runs training by splitting train/test sets\n",
    "    X = [pos_data[i][0] for i in range(len(pos_data))]\n",
    "    Y = [pos_data[i][1] for i in range(len(pos_data))]\n",
    "\n",
    "    X_neg = [neg_data[i][0] for i in range(len(neg_data))]\n",
    "    Y_neg = [neg_data[i][1] for i in range(len(neg_data))]\n",
    "\n",
    "    X.extend(X_neg)\n",
    "    Y.extend(Y_neg)\n",
    "\n",
    "    X_array = np.array(X)\n",
    "    Y_array = np.array(Y)\n",
    "#     X_array = X_array[:, np.r_[:3]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_array, Y_array, test_size=0.01, random_state=42)\n",
    "\n",
    "    test_zero_vals = np.argwhere(y_test == 0)\n",
    "    test_one_vals = np.argwhere(y_test == 1)\n",
    "    print ('test zero vals', len(test_zero_vals), 'test one vals', len(test_one_vals))\n",
    "\n",
    "    zero_vals = np.argwhere(y_train == 0)\n",
    "    one_vals = np.argwhere(y_train == 1)\n",
    "    random_indices = zero_vals[sorted(random.sample(range(len(zero_vals)), len(one_vals)))]\n",
    "    random_indices = np.concatenate([random_indices, one_vals]).reshape(-1)\n",
    "\n",
    "    X_train = X_train[random_indices]\n",
    "    y_train = y_train[random_indices]\n",
    "    print (X_train.shape, y_train.shape)\n",
    "\n",
    "    train_zero_vals = np.argwhere(y_train == 0)\n",
    "    train_one_vals = np.argwhere(y_train == 1)\n",
    "    print ('train zero vals', len(train_zero_vals), 'train one vals', len(train_one_vals))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test zero vals 112185 test one vals 442\n",
      "(83028, 3) (83028,)\n",
      "train zero vals 41514 train one vals 41514\n",
      "test zero vals 187235 test one vals 254\n",
      "(57420, 3) (57420,)\n",
      "train zero vals 28710 train one vals 28710\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = split_data(pos_data, neg_data)\n",
    "_, X_test, _, y_test = split_data(pos_data_test, neg_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---random forest---\n",
      "0.6017247193717782\n",
      "0.7134768981902739\n",
      "0.3399816929228694\n",
      "0.4605194466196815\n",
      "0.863763895301346\n",
      "0.010382441845183336\n",
      "0.3574660633484163\n",
      "0.020178799489144316\n",
      "0.4405965149955464\n",
      "0.0017714285714285714\n",
      "0.7322834645669292\n",
      "0.003534307484751173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bao Tran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                              random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print ('---random forest---')\n",
    "train_predictions = clf.predict(X_train)\n",
    "val_predictions = clf.predict(X_val)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "get_scores(train_predictions, y_train, val_predictions, y_val, test_predictions, y_test)\n",
    "np.savetxt('results/random_forest.txt', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---logistic regression---\n",
      "0.5864045864045864\n",
      "0.6199023933680974\n",
      "0.446716770246182\n",
      "0.5192496150076998\n",
      "0.7287441843946443\n",
      "0.006717127035617157\n",
      "0.4638009049773756\n",
      "0.013242466328606957\n",
      "0.6888670802020386\n",
      "0.002484152818228542\n",
      "0.5708661417322834\n",
      "0.004946779475982533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bao Tran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, y_train)\n",
    "print ('---logistic regression---')\n",
    "# makes predictions\n",
    "train_predictions = clf.predict(X_train)\n",
    "val_predictions = clf.predict(X_val)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "get_scores(train_predictions, y_train, val_predictions, y_val, test_predictions, y_test)\n",
    "np.savetxt('results/logistic_regression.txt', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---svm_rbf---\n",
      "0.5864045864045864\n",
      "0.6199023933680974\n",
      "0.446716770246182\n",
      "0.5192496150076998\n",
      "0.7287441843946443\n",
      "0.006717127035617157\n",
      "0.4638009049773756\n",
      "0.013242466328606957\n",
      "0.6888670802020386\n",
      "0.002484152818228542\n",
      "0.5708661417322834\n",
      "0.004946779475982533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bao Tran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print ('---svm_rbf---')\n",
    "# makes predictions\n",
    "train_predictions = clf.predict(X_train)\n",
    "val_predictions = clf.predict(X_val)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "train_preds = [pred > 0.5 for pred in train_predictions]\n",
    "test_preds = [pred > 0.5 for pred in test_predictions]\n",
    "\n",
    "get_scores(train_predictions, y_train, val_predictions, y_val, test_predictions, y_test)\n",
    "# np.savetxt('results/svm_rbf.txt', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---svm linear---\n",
      "0.5864045864045864\n",
      "0.6199023933680974\n",
      "0.446716770246182\n",
      "0.5192496150076998\n",
      "0.7287441843946443\n",
      "0.006717127035617157\n",
      "0.4638009049773756\n",
      "0.013242466328606957\n",
      "0.6888670802020386\n",
      "0.002484152818228542\n",
      "0.5708661417322834\n",
      "0.004946779475982533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bao Tran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print ('---svm linear---')\n",
    "# makes predictions\n",
    "train_predictions = clf.predict(X_train)\n",
    "val_predictions = clf.predict(X_val)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "train_preds = [pred > 0.5 for pred in train_predictions]\n",
    "test_preds = [pred > 0.5 for pred in test_predictions]\n",
    "\n",
    "get_scores(train_predictions, y_train, val_predictions, y_val, test_predictions, y_test)\n",
    "# np.savetxt('results/svm_linear.txt', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---knn---\n",
      "0.9592667533844005\n",
      "0.9251817492529325\n",
      "0.9993496169966758\n",
      "0.960836537125388\n",
      "0.8559594417018859\n",
      "0.024983444705315754\n",
      "0.9389140271493213\n",
      "0.0486717879551985\n",
      "0.7961960435012188\n",
      "0.0019942795665065993\n",
      "0.2992125984251969\n",
      "0.003962151030941272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bao Tran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print ('---knn---')\n",
    "# makes predictions\n",
    "train_predictions = clf.predict(X_train)\n",
    "val_predictions = clf.predict(X_val)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "train_preds = [pred > 0.5 for pred in train_predictions]\n",
    "test_preds = [pred > 0.5 for pred in test_predictions]\n",
    "\n",
    "get_scores(train_predictions, y_train, val_predictions, y_val, test_predictions, y_test)\n",
    "np.savetxt('results/knn.txt', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---naive bayes---\n",
      "0.5289781760369996\n",
      "0.5216164738014807\n",
      "0.6992580816110228\n",
      "0.5975135335405388\n",
      "0.3606740774940512\n",
      "0.004060984060984061\n",
      "0.6628959276018099\n",
      "0.00807251487767247\n",
      "0.2321042834512958\n",
      "0.0017403966162806823\n",
      "0.9881889763779528\n",
      "0.0034746736437005965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bao Tran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print ('---naive bayes---')\n",
    "# makes predictions\n",
    "train_predictions = clf.predict(X_train)\n",
    "val_predictions = clf.predict(X_val)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "train_preds = [pred > 0.5 for pred in train_predictions]\n",
    "test_preds = [pred > 0.5 for pred in test_predictions]\n",
    "\n",
    "get_scores(train_predictions, y_train, val_predictions, y_val, test_predictions, y_test)\n",
    "np.savetxt('results/naive_bayes.txt', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
